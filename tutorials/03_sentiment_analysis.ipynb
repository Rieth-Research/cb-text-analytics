{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Sentiment Analysis\n",
    "\n",
    "**Goal:** Learn to analyze the tone and sentiment of central bank communications.\n",
    "\n",
    "**What you'll learn:**\n",
    "- What is sentiment analysis?\n",
    "- Using VADER for sentiment scoring\n",
    "- Detecting hawkish vs dovish language\n",
    "- Tracking sentiment over time\n",
    "- Comparing sentiment across banks\n",
    "\n",
    "**Time:** ~1 hour\n",
    "\n",
    "**Key Concept:** In central banking:\n",
    "- **Hawkish** = favoring tighter monetary policy (higher interest rates)\n",
    "- **Dovish** = favoring looser monetary policy (lower interest rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# Load data function\n",
    "def load_statements(directory, bank_name):\n",
    "    statements = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            date_str = filename.replace('.txt', '').replace('-txt', '')\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "            statements.append({\n",
    "                'date': date_str,\n",
    "                'bank': bank_name,\n",
    "                'text': text,\n",
    "                'filename': filename\n",
    "            })\n",
    "    df = pd.DataFrame(statements)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Load both datasets\n",
    "fed_data = load_statements('../usa-central-bank/fomc-statements', 'Fed')\n",
    "nz_data = load_statements('../nz-central-bank/ocr', 'RBNZ')\n",
    "all_data = pd.concat([fed_data, nz_data], ignore_index=True).sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"âœ“ Loaded {len(fed_data)} Fed statements\")\n",
    "print(f\"âœ“ Loaded {len(nz_data)} RBNZ statements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Understanding Sentiment Analysis\n",
    "\n",
    "**Sentiment analysis** determines if text is positive, negative, or neutral.\n",
    "\n",
    "**VADER** (Valence Aware Dictionary and sEntiment Reasoner) is a tool that:\n",
    "- Analyzes text and gives scores from -1 (very negative) to +1 (very positive)\n",
    "- Understands context (\"not good\" is negative, not positive)\n",
    "- Works well on formal text like financial statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Test with sample sentences\n",
    "test_sentences = [\n",
    "    \"The economy is strong and employment is robust.\",\n",
    "    \"Economic activity has been weak and risks remain.\",\n",
    "    \"The Committee maintains its target range.\",\n",
    "    \"Inflation remains elevated and poses significant concerns.\"\n",
    "]\n",
    "\n",
    "print(\"Testing VADER Sentiment Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    scores = analyzer.polarity_scores(sentence)\n",
    "    print(f\"\\nSentence: {sentence}\")\n",
    "    print(f\"  Positive: {scores['pos']:.2f}\")\n",
    "    print(f\"  Negative: {scores['neg']:.2f}\")\n",
    "    print(f\"  Neutral:  {scores['neu']:.2f}\")\n",
    "    print(f\"  Compound: {scores['compound']:.2f} (overall score)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analyze Sentiment of All Statements\n",
    "\n",
    "Let's score every statement in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "    Get sentiment scores for a text.\n",
    "    Returns the compound score (-1 to +1).\n",
    "    \"\"\"\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores['compound']\n",
    "\n",
    "def get_detailed_sentiment(text):\n",
    "    \"\"\"\n",
    "    Get all sentiment scores.\n",
    "    \"\"\"\n",
    "    return analyzer.polarity_scores(text)\n",
    "\n",
    "# Calculate sentiment for all statements\n",
    "all_data['sentiment'] = all_data['text'].apply(get_sentiment)\n",
    "\n",
    "# Add detailed scores\n",
    "sentiment_details = all_data['text'].apply(get_detailed_sentiment)\n",
    "all_data['positive'] = sentiment_details.apply(lambda x: x['pos'])\n",
    "all_data['negative'] = sentiment_details.apply(lambda x: x['neg'])\n",
    "all_data['neutral'] = sentiment_details.apply(lambda x: x['neu'])\n",
    "\n",
    "print(\"âœ“ Sentiment analysis complete!\")\n",
    "all_data[['date', 'bank', 'sentiment', 'positive', 'negative']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Sentiment Distribution\n",
    "\n",
    "Let's see the overall distribution of sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(all_data['sentiment'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Sentiment Score', fontsize=12)\n",
    "plt.ylabel('Number of Statements', fontsize=12)\n",
    "plt.title('Distribution of Sentiment Scores', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='red', linestyle='--', label='Neutral (0)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSentiment Statistics:\")\n",
    "print(f\"  Mean: {all_data['sentiment'].mean():.3f}\")\n",
    "print(f\"  Median: {all_data['sentiment'].median():.3f}\")\n",
    "print(f\"  Min: {all_data['sentiment'].min():.3f}\")\n",
    "print(f\"  Max: {all_data['sentiment'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Sentiment Over Time\n",
    "\n",
    "This is where it gets interesting! Let's track how sentiment changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for each bank\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "for bank in all_data['bank'].unique():\n",
    "    bank_data = all_data[all_data['bank'] == bank]\n",
    "    plt.plot(bank_data['date'], bank_data['sentiment'], \n",
    "             marker='o', label=bank, linewidth=2, markersize=6)\n",
    "\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Sentiment Score', fontsize=12)\n",
    "plt.title('Sentiment of Central Bank Statements Over Time', fontsize=14, fontweight='bold')\n",
    "plt.axhline(y=0, color='gray', linestyle='--', alpha=0.5, label='Neutral')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Interpretation:\")\n",
    "print(\"   - Look for trends: is sentiment becoming more positive or negative?\")\n",
    "print(\"   - Sharp drops might indicate crisis periods (2008, COVID-19)\")\n",
    "print(\"   - Compare banks: do they have similar patterns?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Hawkish vs Dovish Analysis\n",
    "\n",
    "Central bank watchers care about whether statements are hawkish or dovish.\n",
    "\n",
    "We'll create a custom dictionary for monetary policy language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords associated with hawkish (tightening) policy\n",
    "HAWKISH_WORDS = [\n",
    "    'increase', 'raise', 'tighten', 'elevated', 'strong', 'robust',\n",
    "    'accelerating', 'above', 'high', 'rising', 'tightening', 'restrictive'\n",
    "]\n",
    "\n",
    "# Keywords associated with dovish (loosening) policy\n",
    "DOVISH_WORDS = [\n",
    "    'decrease', 'lower', 'ease', 'weak', 'slow', 'below', 'low',\n",
    "    'subdued', 'decline', 'falling', 'accommodative', 'support'\n",
    "]\n",
    "\n",
    "def calculate_hawk_dove_score(text):\n",
    "    \"\"\"\n",
    "    Calculate hawkish vs dovish score.\n",
    "    \n",
    "    Returns:\n",
    "    - Positive score = hawkish\n",
    "    - Negative score = dovish\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Count hawkish words\n",
    "    hawk_count = sum(text_lower.count(word) for word in HAWKISH_WORDS)\n",
    "    \n",
    "    # Count dovish words\n",
    "    dove_count = sum(text_lower.count(word) for word in DOVISH_WORDS)\n",
    "    \n",
    "    # Normalize by text length (per 100 words)\n",
    "    word_count = len(text.split())\n",
    "    if word_count == 0:\n",
    "        return 0\n",
    "    \n",
    "    hawk_score = (hawk_count / word_count) * 100\n",
    "    dove_score = (dove_count / word_count) * 100\n",
    "    \n",
    "    return hawk_score - dove_score\n",
    "\n",
    "# Calculate for all statements\n",
    "all_data['hawk_dove_score'] = all_data['text'].apply(calculate_hawk_dove_score)\n",
    "\n",
    "print(\"Hawk-Dove Score calculated!\")\n",
    "print(\"  Positive = Hawkish (tightening)\")\n",
    "print(\"  Negative = Dovish (easing)\\n\")\n",
    "\n",
    "all_data[['date', 'bank', 'hawk_dove_score']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hawk-dove scores over time\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "for bank in all_data['bank'].unique():\n",
    "    bank_data = all_data[all_data['bank'] == bank]\n",
    "    plt.plot(bank_data['date'], bank_data['hawk_dove_score'], \n",
    "             marker='o', label=bank, linewidth=2, markersize=6)\n",
    "\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Hawk-Dove Score', fontsize=12)\n",
    "plt.title('Hawkish vs Dovish Language Over Time', fontsize=14, fontweight='bold')\n",
    "plt.axhline(y=0, color='gray', linestyle='--', alpha=0.5, label='Neutral')\n",
    "\n",
    "# Add shaded regions\n",
    "plt.fill_between(all_data['date'], 0, 10, alpha=0.1, color='red', label='Hawkish zone')\n",
    "plt.fill_between(all_data['date'], 0, -10, alpha=0.1, color='blue', label='Dovish zone')\n",
    "\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compare Banks\n",
    "\n",
    "Let's compare sentiment patterns between Fed and RBNZ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare average sentiment\n",
    "comparison = all_data.groupby('bank')[['sentiment', 'hawk_dove_score', 'positive', 'negative']].mean()\n",
    "\n",
    "print(\"Average Scores by Central Bank:\")\n",
    "print(\"=\" * 70)\n",
    "print(comparison.round(3))\n",
    "\n",
    "# Create comparison bar chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Sentiment comparison\n",
    "comparison['sentiment'].plot(kind='bar', ax=axes[0], color=['steelblue', 'coral'])\n",
    "axes[0].set_title('Average Sentiment by Bank', fontweight='bold')\n",
    "axes[0].set_ylabel('Sentiment Score')\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Hawk-Dove comparison\n",
    "comparison['hawk_dove_score'].plot(kind='bar', ax=axes[1], color=['steelblue', 'coral'])\n",
    "axes[1].set_title('Average Hawk-Dove Score by Bank', fontweight='bold')\n",
    "axes[1].set_ylabel('Hawk-Dove Score')\n",
    "axes[1].set_xlabel('')\n",
    "axes[1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Find Most Extreme Statements\n",
    "\n",
    "Let's find the most positive, negative, hawkish, and dovish statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_extreme_statement(df, column, ascending=True, label=\"\"):\n",
    "    \"\"\"\n",
    "    Show the most extreme statement based on a score column.\n",
    "    \"\"\"\n",
    "    statement = df.sort_values(column, ascending=ascending).iloc[0]\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{label}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Date: {statement['date'].date()}\")\n",
    "    print(f\"Bank: {statement['bank']}\")\n",
    "    print(f\"Score: {statement[column]:.3f}\")\n",
    "    print(f\"\\nFirst 300 characters:\")\n",
    "    print(statement['text'][:300] + \"...\")\n",
    "\n",
    "# Most positive\n",
    "show_extreme_statement(all_data, 'sentiment', ascending=False, label=\"MOST POSITIVE STATEMENT\")\n",
    "\n",
    "# Most negative\n",
    "show_extreme_statement(all_data, 'sentiment', ascending=True, label=\"MOST NEGATIVE STATEMENT\")\n",
    "\n",
    "# Most hawkish\n",
    "show_extreme_statement(all_data, 'hawk_dove_score', ascending=False, label=\"MOST HAWKISH STATEMENT\")\n",
    "\n",
    "# Most dovish\n",
    "show_extreme_statement(all_data, 'hawk_dove_score', ascending=True, label=\"MOST DOVISH STATEMENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Sentiment Change Detection\n",
    "\n",
    "Let's detect when sentiment shifts significantly from one statement to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate change from previous statement (for each bank separately)\n",
    "for bank in all_data['bank'].unique():\n",
    "    mask = all_data['bank'] == bank\n",
    "    all_data.loc[mask, 'sentiment_change'] = all_data.loc[mask, 'sentiment'].diff()\n",
    "\n",
    "# Find biggest shifts\n",
    "biggest_shifts = all_data.nlargest(10, 'sentiment_change')[['date', 'bank', 'sentiment_change', 'sentiment']]\n",
    "\n",
    "print(\"Top 10 Biggest Positive Sentiment Shifts:\")\n",
    "print(biggest_shifts)\n",
    "\n",
    "print(\"\\nðŸ’¡ These dates might mark important turning points in policy or economic conditions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Create a Sentiment Dashboard\n",
    "\n",
    "Let's create a comprehensive visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# 1. Sentiment over time\n",
    "for bank in all_data['bank'].unique():\n",
    "    bank_data = all_data[all_data['bank'] == bank]\n",
    "    axes[0, 0].plot(bank_data['date'], bank_data['sentiment'], marker='o', label=bank, linewidth=2)\n",
    "axes[0, 0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0, 0].set_title('Sentiment Over Time', fontweight='bold', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Sentiment Score')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Hawk-Dove over time\n",
    "for bank in all_data['bank'].unique():\n",
    "    bank_data = all_data[all_data['bank'] == bank]\n",
    "    axes[0, 1].plot(bank_data['date'], bank_data['hawk_dove_score'], marker='o', label=bank, linewidth=2)\n",
    "axes[0, 1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0, 1].set_title('Hawkish vs Dovish Over Time', fontweight='bold', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Hawk-Dove Score')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Sentiment distribution\n",
    "axes[1, 0].hist([all_data[all_data['bank']=='Fed']['sentiment'], \n",
    "                 all_data[all_data['bank']=='RBNZ']['sentiment']], \n",
    "                label=['Fed', 'RBNZ'], bins=20, alpha=0.7)\n",
    "axes[1, 0].set_title('Sentiment Distribution', fontweight='bold', fontsize=12)\n",
    "axes[1, 0].set_xlabel('Sentiment Score')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 4. Positive vs Negative\n",
    "for bank in all_data['bank'].unique():\n",
    "    bank_data = all_data[all_data['bank'] == bank]\n",
    "    axes[1, 1].scatter(bank_data['positive'], bank_data['negative'], \n",
    "                      label=bank, alpha=0.6, s=50)\n",
    "axes[1, 1].set_title('Positive vs Negative Language', fontweight='bold', fontsize=12)\n",
    "axes[1, 1].set_xlabel('Positive Score')\n",
    "axes[1, 1].set_ylabel('Negative Score')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ What You Learned\n",
    "\n",
    "1. **Sentiment analysis basics**: Using VADER to score text\n",
    "2. **Domain-specific analysis**: Hawkish vs dovish language in monetary policy\n",
    "3. **Time series tracking**: Following sentiment changes over time\n",
    "4. **Comparative analysis**: Comparing different central banks\n",
    "5. **Change detection**: Finding significant shifts in tone\n",
    "6. **Comprehensive visualization**: Creating multi-panel dashboards\n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "\n",
    "In Tutorial 4, we'll learn:\n",
    "- Advanced visualizations (word clouds, heatmaps)\n",
    "- Interactive plots with Plotly\n",
    "- Creating publication-ready charts\n",
    "\n",
    "## ðŸ’¡ Try It Yourself\n",
    "\n",
    "1. Add more hawkish/dovish keywords to improve the score\n",
    "2. Correlate sentiment with actual interest rate decisions\n",
    "3. Create a \"risk\" score based on uncertainty-related words\n",
    "4. Compare sentiment before and after major economic events (2008 crisis, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise space\n",
    "# YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
