{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4: Advanced Visualizations\n",
    "\n",
    "**Goal:** Learn to create compelling, publication-ready visualizations of text analytics.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Word clouds for visual impact\n",
    "- Heatmaps for pattern detection\n",
    "- Interactive plots with Plotly\n",
    "- Multi-dimensional visualizations\n",
    "- Export-ready charts\n",
    "\n",
    "**Time:** ~1 hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Load data function\n",
    "def load_statements(directory, bank_name):\n",
    "    statements = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            date_str = filename.replace('.txt', '').replace('-txt', '')\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "            statements.append({'date': date_str, 'bank': bank_name, 'text': text})\n",
    "    df = pd.DataFrame(statements)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Load and process data\n",
    "fed_data = load_statements('../usa-central-bank/fomc-statements', 'Fed')\n",
    "nz_data = load_statements('../nz-central-bank/ocr', 'RBNZ')\n",
    "all_data = pd.concat([fed_data, nz_data], ignore_index=True).sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Add sentiment\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "all_data['sentiment'] = all_data['text'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "all_data['word_count'] = all_data['text'].str.split().str.len()\n",
    "\n",
    "print(f\"âœ“ Loaded {len(all_data)} statements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Word Clouds\n",
    "\n",
    "**Word clouds** are visual representations where word size = frequency.\n",
    "They're great for presentations and reports!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordcloud(text, title=\"Word Cloud\"):\n",
    "    \"\"\"\n",
    "    Create a word cloud from text.\n",
    "    \"\"\"\n",
    "    # Define stop words\n",
    "    stop_words = set(['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\n",
    "                      'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',\n",
    "                      'be', 'have', 'has', 'had', 'will', 'would', 'committee'])\n",
    "    \n",
    "    # Generate word cloud\n",
    "    wordcloud = WordCloud(\n",
    "        width=1200,\n",
    "        height=600,\n",
    "        background_color='white',\n",
    "        stopwords=stop_words,\n",
    "        colormap='viridis',\n",
    "        max_words=100,\n",
    "        relative_scaling=0.5\n",
    "    ).generate(text)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=18, fontweight='bold', pad=20)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()\n",
    "\n",
    "# Create word clouds for each bank\n",
    "fed_text = ' '.join(fed_data['text'])\n",
    "nz_text = ' '.join(nz_data['text'])\n",
    "\n",
    "create_wordcloud(fed_text, \"Federal Reserve FOMC Statements (2014-2017)\")\n",
    "create_wordcloud(nz_text, \"Reserve Bank of New Zealand OCR Statements (2006-2012)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Heatmaps - Keyword Intensity Over Time\n",
    "\n",
    "Heatmaps show patterns across two dimensions. Perfect for tracking multiple keywords over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keywords to track\n",
    "keywords = ['inflation', 'employment', 'growth', 'risk', 'uncertainty', \n",
    "            'economic', 'policy', 'financial', 'market', 'recovery']\n",
    "\n",
    "# Count keywords in Fed statements\n",
    "keyword_data = fed_data[['date']].copy()\n",
    "for keyword in keywords:\n",
    "    keyword_data[keyword] = fed_data['text'].str.lower().str.count(keyword)\n",
    "\n",
    "# Create heatmap matrix\n",
    "# Rows = dates, Columns = keywords\n",
    "heatmap_matrix = keyword_data.set_index('date')[keywords]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(heatmap_matrix, \n",
    "            cmap='YlOrRd',\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={'label': 'Mentions'},\n",
    "            fmt='d')\n",
    "plt.title('Keyword Frequency Heatmap - Fed Statements', fontsize=14, fontweight='bold', pad=15)\n",
    "plt.xlabel('Keywords', fontsize=11)\n",
    "plt.ylabel('Date', fontsize=11)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Look for:\")\n",
    "print(\"   - Vertical bands = a keyword used heavily in that period\")\n",
    "print(\"   - Horizontal bands = a statement mentioning many keywords\")\n",
    "print(\"   - Patterns = correlations between keywords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Interactive Plots with Plotly\n",
    "\n",
    "**Plotly** creates interactive charts you can zoom, pan, and hover over.\n",
    "Perfect for exploring data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive scatter plot: Word count vs Sentiment\n",
    "fig = px.scatter(all_data, \n",
    "                 x='word_count', \n",
    "                 y='sentiment',\n",
    "                 color='bank',\n",
    "                 hover_data=['date'],\n",
    "                 title='Statement Length vs Sentiment',\n",
    "                 labels={'word_count': 'Word Count', 'sentiment': 'Sentiment Score'},\n",
    "                 template='plotly_white',\n",
    "                 width=900,\n",
    "                 height=600)\n",
    "\n",
    "fig.update_traces(marker=dict(size=10, opacity=0.7))\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Neutral\")\n",
    "fig.show()\n",
    "\n",
    "print(\"ðŸ’¡ TIP: Hover over points to see details, click legend to filter, drag to zoom!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive time series with range slider\n",
    "fig = go.Figure()\n",
    "\n",
    "for bank in all_data['bank'].unique():\n",
    "    bank_data = all_data[all_data['bank'] == bank]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=bank_data['date'],\n",
    "        y=bank_data['sentiment'],\n",
    "        mode='lines+markers',\n",
    "        name=bank,\n",
    "        hovertemplate='<b>%{fullData.name}</b><br>Date: %{x|%Y-%m-%d}<br>Sentiment: %{y:.3f}<extra></extra>'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Interactive Sentiment Timeline',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Sentiment Score',\n",
    "    hovermode='x unified',\n",
    "    template='plotly_white',\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                dict(step=\"all\", label=\"All\")\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(visible=True),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"ðŸ’¡ Use the range slider at the bottom to zoom into specific periods!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Multi-Dimensional Analysis\n",
    "\n",
    "Let's visualize multiple metrics simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bubble chart: x=word count, y=sentiment, size=date (newer = bigger), color=bank\n",
    "all_data['year'] = all_data['date'].dt.year\n",
    "all_data['days_since_start'] = (all_data['date'] - all_data['date'].min()).dt.days\n",
    "\n",
    "fig = px.scatter(all_data,\n",
    "                 x='word_count',\n",
    "                 y='sentiment',\n",
    "                 size='days_since_start',\n",
    "                 color='bank',\n",
    "                 hover_data=['date', 'year'],\n",
    "                 title='Multi-Dimensional View: Length, Sentiment, Time, and Bank',\n",
    "                 labels={'word_count': 'Statement Length (words)', \n",
    "                        'sentiment': 'Sentiment Score',\n",
    "                        'days_since_start': 'Time progression'},\n",
    "                 template='plotly_white',\n",
    "                 width=1000,\n",
    "                 height=600)\n",
    "\n",
    "fig.update_traces(marker=dict(opacity=0.6, line=dict(width=1, color='DarkSlateGrey')))\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Bubble size = how recent (bigger = more recent)\")\n",
    "print(\"   This shows if statements are getting longer/shorter and more/less positive over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Comparison Dashboard\n",
    "\n",
    "Create a comprehensive comparison dashboard with Plotly subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Sentiment Over Time', 'Statement Length Distribution',\n",
    "                    'Word Count Over Time', 'Sentiment Distribution'),\n",
    "    specs=[[{'type': 'scatter'}, {'type': 'histogram'}],\n",
    "           [{'type': 'scatter'}, {'type': 'box'}]]\n",
    ")\n",
    "\n",
    "colors = {'Fed': '#1f77b4', 'RBNZ': '#ff7f0e'}\n",
    "\n",
    "# 1. Sentiment over time\n",
    "for bank in all_data['bank'].unique():\n",
    "    bank_data = all_data[all_data['bank'] == bank]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=bank_data['date'], y=bank_data['sentiment'], \n",
    "                  name=bank, line=dict(color=colors[bank]), showlegend=True),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# 2. Statement length distribution\n",
    "for bank in all_data['bank'].unique():\n",
    "    bank_data = all_data[all_data['bank'] == bank]\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=bank_data['word_count'], name=bank, \n",
    "                    marker=dict(color=colors[bank]), showlegend=False, opacity=0.7),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# 3. Word count over time\n",
    "for bank in all_data['bank'].unique():\n",
    "    bank_data = all_data[all_data['bank'] == bank]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=bank_data['date'], y=bank_data['word_count'], \n",
    "                  name=bank, line=dict(color=colors[bank]), showlegend=False),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# 4. Sentiment distribution (box plot)\n",
    "for bank in all_data['bank'].unique():\n",
    "    bank_data = all_data[all_data['bank'] == bank]\n",
    "    fig.add_trace(\n",
    "        go.Box(y=bank_data['sentiment'], name=bank, \n",
    "              marker=dict(color=colors[bank]), showlegend=False),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text=\"Central Bank Communications Dashboard\",\n",
    "    height=800,\n",
    "    showlegend=True,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Word Count\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Bank\", row=2, col=2)\n",
    "\n",
    "fig.update_yaxes(title_text=\"Sentiment\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Word Count\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Sentiment\", row=2, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Correlation Heatmap\n",
    "\n",
    "See how different metrics relate to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more metrics\n",
    "all_data['sentence_count'] = all_data['text'].str.count(r'[.!?]')\n",
    "all_data['avg_word_length'] = all_data['text'].str.len() / all_data['word_count']\n",
    "all_data['inflation_mentions'] = all_data['text'].str.lower().str.count('inflation')\n",
    "all_data['employment_mentions'] = all_data['text'].str.lower().str.count('employment')\n",
    "\n",
    "# Select numeric columns for correlation\n",
    "corr_columns = ['sentiment', 'word_count', 'sentence_count', 'avg_word_length', \n",
    "                'inflation_mentions', 'employment_mentions']\n",
    "correlation_matrix = all_data[corr_columns].corr()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True,  # Show numbers\n",
    "            fmt='.2f',\n",
    "            cmap='coolwarm',\n",
    "            center=0,\n",
    "            square=True,\n",
    "            linewidths=1,\n",
    "            cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Correlation Between Metrics', fontsize=14, fontweight='bold', pad=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Reading correlations:\")\n",
    "print(\"   1.0 = perfect positive correlation\")\n",
    "print(\"   0.0 = no correlation\")\n",
    "print(\"   -1.0 = perfect negative correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Time Series Decomposition\n",
    "\n",
    "Break down sentiment into trend and seasonal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling average (smoothed trend)\n",
    "for bank in all_data['bank'].unique():\n",
    "    mask = all_data['bank'] == bank\n",
    "    all_data.loc[mask, 'sentiment_trend'] = all_data.loc[mask, 'sentiment'].rolling(window=5, center=True).mean()\n",
    "\n",
    "# Plot original vs trend\n",
    "fig = make_subplots(rows=2, cols=1, \n",
    "                    subplot_titles=('Federal Reserve', 'Reserve Bank of New Zealand'),\n",
    "                    shared_xaxes=True)\n",
    "\n",
    "for i, bank in enumerate(['Fed', 'RBNZ'], 1):\n",
    "    bank_data = all_data[all_data['bank'] == bank]\n",
    "    \n",
    "    # Original\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=bank_data['date'], y=bank_data['sentiment'],\n",
    "                  name=f'{bank} Raw', mode='lines',\n",
    "                  line=dict(color='lightblue', width=1), opacity=0.5),\n",
    "        row=i, col=1\n",
    "    )\n",
    "    \n",
    "    # Trend\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=bank_data['date'], y=bank_data['sentiment_trend'],\n",
    "                  name=f'{bank} Trend', mode='lines',\n",
    "                  line=dict(color='darkblue', width=3)),\n",
    "        row=i, col=1\n",
    "    )\n",
    "\n",
    "fig.update_layout(title='Sentiment: Raw vs Smoothed Trend', \n",
    "                 height=700, template='plotly_white')\n",
    "fig.update_yaxes(title_text=\"Sentiment Score\")\n",
    "fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ The trend line reveals the overall direction, filtering out noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Export-Ready Publication Charts\n",
    "\n",
    "Create professional charts ready for reports or presentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-quality chart with custom styling\n",
    "plt.figure(figsize=(14, 7), dpi=300)  # High resolution\n",
    "\n",
    "# Plot data\n",
    "for bank in all_data['bank'].unique():\n",
    "    bank_data = all_data[all_data['bank'] == bank]\n",
    "    plt.plot(bank_data['date'], bank_data['sentiment'], \n",
    "             marker='o', label=bank, linewidth=2.5, markersize=7, alpha=0.8)\n",
    "\n",
    "# Styling\n",
    "plt.axhline(y=0, color='gray', linestyle='--', alpha=0.5, linewidth=1.5, label='Neutral')\n",
    "plt.xlabel('Date', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Sentiment Score', fontsize=14, fontweight='bold')\n",
    "plt.title('Sentiment Analysis of Central Bank Communications\\n2006-2017', \n",
    "         fontsize=16, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=12, frameon=True, shadow=True, loc='best')\n",
    "plt.grid(True, alpha=0.3, linestyle=':', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "plt.savefig('sentiment_analysis_chart.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Chart saved as 'sentiment_analysis_chart.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Interactive HTML Export\n",
    "\n",
    "Save interactive Plotly charts as HTML files you can share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive interactive chart\n",
    "fig = px.line(all_data, \n",
    "              x='date', \n",
    "              y='sentiment', \n",
    "              color='bank',\n",
    "              title='Central Bank Sentiment Analysis - Interactive Dashboard',\n",
    "              labels={'date': 'Date', 'sentiment': 'Sentiment Score', 'bank': 'Central Bank'},\n",
    "              template='plotly_white')\n",
    "\n",
    "fig.update_traces(mode='lines+markers')\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Neutral\")\n",
    "\n",
    "# Save as HTML\n",
    "fig.write_html('sentiment_dashboard.html')\n",
    "print(\"âœ“ Interactive dashboard saved as 'sentiment_dashboard.html'\")\n",
    "print(\"  Open this file in a web browser to explore!\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ What You Learned\n",
    "\n",
    "1. **Word clouds**: Visual representation of text frequency\n",
    "2. **Heatmaps**: Pattern detection across dimensions\n",
    "3. **Interactive plots**: Plotly for explorable visualizations\n",
    "4. **Multi-dimensional analysis**: Bubble charts and subplots\n",
    "5. **Statistical visualizations**: Correlations and distributions\n",
    "6. **Time series decomposition**: Trend analysis\n",
    "7. **Export techniques**: Publication-ready charts and HTML dashboards\n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "\n",
    "You now have a complete toolkit for text analytics! Consider:\n",
    "- Building a complete analysis pipeline\n",
    "- Creating a web dashboard with Streamlit or Dash\n",
    "- Adding more advanced NLP (topic modeling, entity recognition)\n",
    "- Integrating with real-time data sources\n",
    "\n",
    "## ðŸ’¡ Try It Yourself\n",
    "\n",
    "1. Create a word cloud comparing early vs late periods\n",
    "2. Build a heatmap for RBNZ statements\n",
    "3. Make an animated Plotly chart showing sentiment evolution\n",
    "4. Design your own custom dashboard combining all techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise space\n",
    "# YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
